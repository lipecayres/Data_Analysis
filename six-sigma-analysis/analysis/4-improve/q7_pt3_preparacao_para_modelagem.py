# -*- coding: utf-8 -*-
"""Q7_pt3_Preparacao_para_modelagem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E9762cTcXXsyknlAO-pFCbV704XP7-yx

#**Preparação para modelagem**
"""

#Importar arquivo chamado "Dados_pre_processados"
from google.colab import files
uploaded = files.upload()

"""**Bibliotecas utilizadas**"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.utils import np_utils

"""**Importar dados pre processados**"""

dataset = pd.read_csv("Dados_pre_processados.csv")
dataset.shape

"""**Divisão da base utilizada**"""

## Codificação da variavel resposta

dataset.loc[dataset["class"] == "Setosa", "class"] = 0
dataset.loc[dataset["class"] == "Versicolor", "class"] = 1
dataset.loc[dataset["class"] == "Virginica", "class"] = 2

## Separação da variavel resposta

X = dataset.loc[:, ['sepal-length', 'sepal-width', 'petal-length', 'petal-width']].values
Y = dataset['class'].values

## Normalização dos dados

sc = StandardScaler()
X = sc.fit_transform(X)

## Divisão em base de treinamento e teste

X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(X, Y, test_size = 0.25)

## Criação de variaveis dummy para a variavel Y

y_treinamento = np_utils.to_categorical(y_treinamento, num_classes = 3)
y_teste = np_utils.to_categorical(y_teste, num_classes = 3)

"""**Salvando dados**"""

import pickle
# Gravando os dados para o modelo
pickle.dump((X_treinamento, y_treinamento, X_teste, y_teste), open('Dados_para_modelo.sav', 'wb'))

files.download('Dados_para_modelo.sav')

